Thoughts on code comments

Although it can make the code ugly, it’s always better to have too many comments than too few. The goal is always to sustain maintainability such that there is very little wasted engineering effort i.e. someone with no prior knowledge of the project (but sufficient expertise in software development) can follow what is going on inside a program without needing to work it out for themselves.

This is difficult to achieve and needs to be performed in combination with good choice on variable, object, method names and intuitive project structure (single purpose files supported by headers, implementations in one or the other, one class per file etc.) and by keeping complexity low (as few classes as necessary with simple inheritance, relationships, design patterns). Blocks of code doing certain tasks within methods (e.g. applying a rotation matrix to an array) should be supported by comments before the block begin. If splitting blocks follows a similar pattern to splitting paragraphs then the comment serves as an introduction and should be able to outline the task/data object/transformation the code is now focusing on (analogous to time/place/person). 

In addition we need to consider doc strings as a separate subclass of comment which provide in-code explanation of input/output variables and purpose of each method, class, etc.. So not only are we creating automatic documentation but we are also making it easier for the uninitiated to follow what the code is doing. Combined with a clear variable name describing the limited scope of the method, it should be unnecessary to inspect the blocks of code which form the method to determine what the method is doing to it’s inputs and what any output represents. 

We should also include comments which define the test specifications --- they could be similar to the doc strings for methods where the in/out variable explanation is replaced by the file dependencies (e.g. config files, model files), the target class/method/function/file which the test is designed to ensure works, the issue that the test proved was fixed, any conditions about the system for test success/failure (e.g. <test_name> fixes/adds feature support for issue207 and ensures volume of ellipsoid is unchanged after rotation of axes). This size of these lists will likely be different for unit tests and integration tests and some of these categories may not be applicable for all tests. The goal is to allow an uninitiated user to locate the point of failure when a test fails during CI or when validating a local install/compile and to aid anyone when reporting and fixing a bug. These are more important for integration tests where the test target is obscured by interaction with other code. 

When a bug is identified it can either be fixed straight away or the test can get filtered (turned off so as to not break CI) and a follow-up task/issue created (note: in a small organisation where code is merged infrequently and CI tests are run on a per change basis, it would be more likely you would fix the bug rather than track an issue). Additionally, if you leave a TODO/FIXME in the code where the change is too large or outside the scope of the current work, you should also create a follow-up task/issue. In both cases the issue number should be included in the comment so that a quick search can be performed to help identify the requirements for that feature/issue and to make sure the issue has been fully addressed before making a submission/pull request. In some CI systems, a submission will be blocked or require a new follow-up task to be linked to the failure and other automatic checks will fail if the linked issue is present anywhere in the code base. 



